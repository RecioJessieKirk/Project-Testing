{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## YOLOV5 FINE TUNING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### COCO DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   0%|          | 0/100 [00:00<?, ?epoch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error decoding JSON from C:\\Users\\Kirk Recio\\AppData\\Roaming\\Ultralytics\\persistent_cache.json. Starting with an empty dictionary.\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5nu.pt, cfg=, data=dataset.yaml, hyp=yolov5\\data\\hyps\\hyp.scratch-low.yaml, epochs=100, batch_size=16, imgsz=640, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, evolve_population=yolov5\\data\\hyps, resume_evolve=None, bucket=, cache=None, image_weights=False, device=cuda, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=4, project=yolov5\\runs\\train, name=exp, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest, ndjson_console=False, ndjson_file=False\n",
      "\u001b[34m\u001b[1mgithub: \u001b[0m YOLOv5 is out of date by 5 commits. Use 'git pull' or 'git clone https://github.com/ultralytics/yolov5' to update.\n",
      "fatal: cannot change to 'C:\\Users\\Kirk': Invalid argument\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Kirk Recio\\Documents\\PYTHON\\Project Testing\\Data Cleaning Training\\yolov5\\train.py\", line 986, in <module>\n",
      "    main(opt)\n",
      "  File \"c:\\Users\\Kirk Recio\\Documents\\PYTHON\\Project Testing\\Data Cleaning Training\\yolov5\\train.py\", line 672, in main\n",
      "    device = select_device(opt.device, batch_size=opt.batch_size)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Kirk Recio\\Documents\\PYTHON\\Project Testing\\Data Cleaning Training\\yolov5\\utils\\torch_utils.py\", line 124, in select_device\n",
      "    assert torch.cuda.is_available() and torch.cuda.device_count() >= len(device.replace(\",\", \"\")), (\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AssertionError: Invalid CUDA '--device cuda' requested, use '--device cpu' or pass valid CUDA device(s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   0%|          | 0/100 [00:15<?, ?epoch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Training completed!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "import re\n",
    "import time\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Set paths\n",
    "DATASET_YAML = \"dataset.yaml\"  # Update if needed\n",
    "MODEL_PATH = \"yolov5nu.pt\"  # Pre-trained YOLOv5 model\n",
    "EPOCHS = 100  # Training epochs\n",
    "BATCH_SIZE = 16  # Adjust based on GPU memory\n",
    "IMG_SIZE = 640  # Image size\n",
    "DEVICE = \"cuda\"  # Use \"cpu\" if no GPU\n",
    "WORKERS = str(min(4, max(1, os.cpu_count() // 2)))  # Auto-set workers\n",
    "\n",
    "# Training command\n",
    "command = [\n",
    "    \"python\", \"yolov5/train.py\",\n",
    "    \"--img\", str(IMG_SIZE),\n",
    "    \"--batch\", str(BATCH_SIZE),\n",
    "    \"--epochs\", str(EPOCHS),\n",
    "    \"--data\", DATASET_YAML,\n",
    "    \"--weights\", MODEL_PATH,\n",
    "    \"--device\", DEVICE,\n",
    "    \"--workers\", WORKERS\n",
    "]\n",
    "\n",
    "# Initialize tqdm progress bar\n",
    "pbar = tqdm(total=EPOCHS, desc=\"Training Progress\", unit=\"epoch\", dynamic_ncols=True)\n",
    "\n",
    "# Start training process\n",
    "start_time = time.time()\n",
    "with subprocess.Popen(command, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True, bufsize=1) as process:\n",
    "    for line in process.stdout:\n",
    "        print(line, end=\"\")  # Print training logs in real-time\n",
    "\n",
    "        # Match YOLOv5 epoch progress\n",
    "        match = re.search(r\"Epoch\\s+(\\d+)/(\\d+)\", line)\n",
    "        if match:\n",
    "            current_epoch = int(match.group(1))\n",
    "            total_epochs = int(match.group(2))\n",
    "\n",
    "            # Update tqdm progress bar\n",
    "            pbar.n = current_epoch\n",
    "            elapsed_time = time.time() - start_time\n",
    "            avg_time_per_epoch = elapsed_time / max(1, current_epoch)\n",
    "            remaining_time = avg_time_per_epoch * (total_epochs - current_epoch)\n",
    "\n",
    "            pbar.set_description(f\"Training Progress ‚è≥ {remaining_time:.2f} sec remaining\")\n",
    "            pbar.update(1)  # Move progress forward\n",
    "\n",
    "pbar.close()\n",
    "process.wait()  # Ensure process finishes\n",
    "print(\"\\n‚úÖ Training completed!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Volume in drive C is Acer\n",
      " Volume Serial Number is 8460-89F9\n",
      "\n",
      " Directory of c:\\Users\\Kirk Recio\\Documents\\PYTHON\\Project Testing\\Data Cleaning Training\\yolov5\n",
      "\n",
      "03/24/2025  03:01 PM    <DIR>          .\n",
      "03/24/2025  05:51 PM    <DIR>          ..\n",
      "03/24/2025  01:20 PM             3,923 .dockerignore\n",
      "03/24/2025  01:20 PM                77 .gitattributes\n",
      "03/24/2025  01:20 PM    <DIR>          .github\n",
      "03/24/2025  01:20 PM             4,268 .gitignore\n",
      "03/24/2025  01:27 PM    <DIR>          __pycache__\n",
      "03/24/2025  01:20 PM            14,440 benchmarks.py\n",
      "03/24/2025  01:20 PM               407 CITATION.cff\n",
      "03/24/2025  01:20 PM    <DIR>          classify\n",
      "03/24/2025  01:20 PM             5,082 CONTRIBUTING.md\n",
      "03/24/2025  01:20 PM    <DIR>          data\n",
      "03/24/2025  01:20 PM            24,199 detect.py\n",
      "03/24/2025  01:20 PM            70,122 export.py\n",
      "03/24/2025  01:20 PM            24,504 hubconf.py\n",
      "03/24/2025  01:20 PM            35,184 LICENSE\n",
      "03/24/2025  01:27 PM    <DIR>          models\n",
      "03/24/2025  01:20 PM             5,550 pyproject.toml\n",
      "03/24/2025  01:20 PM            43,990 README.md\n",
      "03/24/2025  01:20 PM            44,010 README.zh-CN.md\n",
      "03/24/2025  01:20 PM             1,647 requirements.txt\n",
      "03/24/2025  02:10 PM    <DIR>          runs\n",
      "03/24/2025  01:20 PM    <DIR>          segment\n",
      "03/24/2025  01:20 PM            48,143 train.py\n",
      "03/24/2025  01:20 PM            42,051 tutorial.ipynb\n",
      "03/24/2025  01:28 PM    <DIR>          utils\n",
      "03/24/2025  01:20 PM            31,053 val.py\n",
      "11/21/2024  06:49 PM         5,562,759 yolov5nu.pt\n",
      "              18 File(s)      5,961,409 bytes\n",
      "              10 Dir(s)  14,769,971,200 bytes free\n"
     ]
    }
   ],
   "source": [
    "%ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### COCO DATASET 2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train': '../cocosubset/train2017', 'val': '../cocosubset/val2017', 'nc': 80, 'names': ['person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus', 'train', 'truck', 'boat', 'traffic light', 'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow', 'elephant', 'bear', 'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie', 'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard', 'tennis racket', 'bottle', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple', 'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair', 'couch', 'potted plant', 'bed', 'dining table', 'toilet', 'TV', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone', 'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors', 'teddy bear', 'hair drier', 'toothbrush']}\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "print(yaml.safe_load(open(\"dataset.yaml\")))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ALMOST WORKING "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Kirk Recio\\Documents\\PYTHON\\Project Testing\\Data Cleaning Training\n",
      "c:\\Users\\Kirk Recio\\Documents\\PYTHON\\Project Testing\\Data Cleaning Training\\yolov5\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "%cd ..\n",
    "%cd yolov5\n",
    "!python train.py --data ../cocosubset/dataset.yaml --weights yolov5n.pt --epochs 1 --batch-size 16 --verbose\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Deleted old cache file!\n"
     ]
    }
   ],
   "source": [
    "cache_file = r\"C:\\Users\\Kirk Recio\\Documents\\PYTHON\\Project Testing\\Data Cleaning Training\\cocosubset\\train2017.cache\"\n",
    "\n",
    "if os.path.exists(cache_file):\n",
    "    os.remove(cache_file)\n",
    "    print(\"‚úÖ Deleted old cache file!\")\n",
    "else:\n",
    "    print(\"‚ùå Cache file not found!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Select YOLOv5 üöÄ logger {run: 'auto'}\n",
    "logger = 'Tensorboard' #@param ['Comet', 'ClearML', 'TensorBoard']\n",
    "\n",
    "if logger == 'Comet':\n",
    "  %pip install -q comet_ml\n",
    "  import comet_ml; comet_ml.init()\n",
    "elif logger == 'ClearML':\n",
    "  %pip install -q clearml\n",
    "  import clearml; clearml.browser_login()\n",
    "elif logger == 'TensorBoard':\n",
    "  %load_ext tensorboard\n",
    "  %tensorboard --logdir runs/train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "# %cd Data Cleaning Training\n",
    "# %cd yolov5\n",
    "# !python train.py --data ../cocosubset/dataset.yaml --weights yolov5n.pt --epochs 1 --batch-size 16 --cache\n",
    "\n",
    "# !python train.py --img 640 --batch 16 --epochs 1 ../cocosubset/dataset.yaml --weights yolov5n.pt --cache\n",
    "!python train.py --img 640 --batch 16 --epochs 1 --data dataset.yaml --weights yolov5n.pt --cache\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### END OF ALMOST WORKING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WinError 2] The system cannot find the file specified: 'yolov5'\n",
      "c:\\Users\\Kirk Recio\\Documents\\PYTHON\\Project Testing\\Data Cleaning Training\\yolov5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5nu.pt, cfg=, data=../dataset.yaml, hyp=data\\hyps\\hyp.scratch-low.yaml, epochs=50, batch_size=16, imgsz=640, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, evolve_population=data\\hyps, resume_evolve=None, bucket=, cache=None, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=runs\\train, name=exp, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest, ndjson_console=False, ndjson_file=False\n",
      "\u001b[34m\u001b[1mgithub: \u001b[0mup to date with https://github.com/ultralytics/yolov5 \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Kirk Recio\\Documents\\PYTHON\\Project Testing\\Data Cleaning Training\\yolov5\\train.py\", line 986, in <module>\n",
      "    main(opt)\n",
      "  File \"c:\\Users\\Kirk Recio\\Documents\\PYTHON\\Project Testing\\Data Cleaning Training\\yolov5\\train.py\", line 656, in main\n",
      "    check_file(opt.data),\n",
      "    ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Kirk Recio\\Documents\\PYTHON\\Project Testing\\Data Cleaning Training\\yolov5\\utils\\general.py\", line 506, in check_file\n",
      "    assert len(files), f\"File not found: {file}\"  # assert file was found\n",
      "           ^^^^^^^^^^\n",
      "AssertionError: File not found: ../dataset.yaml\n"
     ]
    }
   ],
   "source": [
    "%cd yolov5\n",
    "!python train.py --img 640 --batch 16 --epochs 50 --data ../dataset.yaml --weights yolov5nu.pt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "NVIDIA GeForce RTX 3050 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())  # Should print True\n",
    "print(torch.cuda.get_device_name(0))  # Should print your GPU name\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### POTHOLE DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üöÄ Training completed in 20.39 seconds (0.34 minutes)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "# Start timing\n",
    "start_time = time.time()\n",
    "\n",
    "# Run YOLOv5 training\n",
    "os.system(\"python yolov5/train.py --weights yolov5s.pt --data pothole.yaml --epochs 100 --batch-size 16 --save-period 10\")\n",
    "\n",
    "# Calculate elapsed time\n",
    "elapsed_time = time.time() - start_time\n",
    "print(f\"\\nüöÄ Training completed in {elapsed_time:.2f} seconds ({elapsed_time / 60:.2f} minutes)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EASY OCR "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ICDAR 2015 DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
